{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import *\n",
    "import glob\n",
    "import scipy \n",
    "from datetime import datetime as dt\n",
    "import sklearn\n",
    "sns.style = 'darkgrid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stress(level):\n",
    "    \"\"\"\n",
    "    converts input stress level from the scale above into a more usable scale with 1 being feeling great \n",
    "    and 5 being stressed out.\n",
    "    \"\"\"\n",
    "    # little stress = 3/5 stressed\n",
    "    if level == 1: \n",
    "        return 3\n",
    "    # definitely stressed = 4/5\n",
    "    if level == 2:\n",
    "        return 4\n",
    "    # stressed out = 5/5\n",
    "    if level == 3:\n",
    "        return 5\n",
    "    # feeling good = 2/5\n",
    "    if level == 4: \n",
    "        return 2\n",
    "    # feeling great = 1/5 \n",
    "    if level == 5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_variance(gps_df):\n",
    "    \"\"\"\n",
    "    returns the location variance of the gps dataframe, which is log(variance of latitiude squared plus variance of \n",
    "    longitude squared)\n",
    "    \"\"\"\n",
    "    num =  gps_df['lon'].var() + gps_df['lat'].var()\n",
    "    return log(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stress_ema_remove_null(uid, ema_name, desired_column): \n",
    "    \"\"\"\n",
    "    input: uid for which we want to process the stress EMA\n",
    "    \"\"\"\n",
    "    ema = pd.read_json('dataset/EMA/response/{}/{}_{}.json'.format(ema_name, ema_name, uid))\n",
    "    \n",
    "    try: \n",
    "        ema[desired_column] = ema[desired_column].where(np.isfinite, ema.null)\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "        \n",
    "    ema[desired_column] = pd.to_numeric(ema[desired_column], errors='coerce')\n",
    "    \n",
    "    ema = ema[['resp_time', desired_column]]\n",
    "    ema = ema.dropna()\n",
    "    \n",
    "    if ema_name == 'stress' or ema_name == 'Stress': \n",
    "        ema['level'] = ema['level'].apply(convert_stress)\n",
    "    \n",
    "    return ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_changes(wifi_locations): \n",
    "    changes = -1\n",
    "    previous = None\n",
    "    \n",
    "    for location in wifi_locations['location'].values: \n",
    "        if location != previous:\n",
    "            changes += 1\n",
    "            previous = location\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_in_range(start, end, x):\n",
    "    \"\"\"Return true if x is in the range [start, end]\"\"\"\n",
    "    if start <= end:\n",
    "        return start <= x <= end\n",
    "    else:\n",
    "        return start <= x or x <= end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_activity(uid): \n",
    "    # load activity data\n",
    "    activity = pd.read_csv('dataset/sensing/activity/activity_' + uid + '.csv')\n",
    "    activity['time'] = pd.to_datetime(activity['timestamp'], unit = 's') \n",
    "    activity['day'] = activity['time'].dt.dayofyear\n",
    "    activity = activity[activity[' activity inference'] != 3]\n",
    "    return activity\n",
    "\n",
    "def load_conversation(uid): \n",
    "    # load conversation data\n",
    "    conversation = pd.read_csv('dataset/sensing/conversation/conversation_' + uid + '.csv')\n",
    "    conversation['convo duration'] = conversation[' end_timestamp'] - conversation['start_timestamp']\n",
    "    conversation['day'] = pd.to_datetime(conversation['start_timestamp'], unit = 's').dt.dayofyear\n",
    "    return conversation\n",
    "\n",
    "def load_darkness(uid): \n",
    "    # load darkness data\n",
    "    darkness = pd.read_csv('dataset/sensing/dark/dark_' + uid + '.csv')\n",
    "    darkness['day'] = pd.to_datetime(darkness['start'], unit = 's').dt.dayofyear\n",
    "    darkness['duration'] = darkness['end'] - darkness['start']\n",
    "    return darkness\n",
    "\n",
    "def load_bluetooth(uid):\n",
    "    # load bluetooth data\n",
    "    bluetooth = pd.read_csv('dataset/sensing/bluetooth/bt_' + uid + '.csv')\n",
    "    bluetooth['time'] = pd.to_datetime(bluetooth['time'], unit = 's')\n",
    "    bluetooth['day'] = bluetooth['time'].dt.dayofyear\n",
    "    return bluetooth\n",
    "\n",
    "def load_gps(uid):\n",
    "    # gps data \n",
    "    gps = pd.read_csv('dataset/sensing/gps/gps_' + uid + '.csv')\n",
    "    # data is out of order, this will reformat it. \n",
    "    gps.reset_index(inplace = True)\n",
    "    gps.columns = ('timestamp', 'provider', 'network_type', 'accuracy', 'lat',\n",
    "                   'lon', 'altitude', 'bearing' ,'speed', 'travelstate', 'null')\n",
    "    gps = gps.drop(\"null\", 1)\n",
    "    gps['time'] = pd.to_datetime(gps['timestamp'], unit = 's')\n",
    "    gps['day'] = gps['time'].dt.dayofyear\n",
    "    return gps\n",
    "\n",
    "def load_wifi_locations(uid): \n",
    "    # wifi locations data\n",
    "    wifi_locations = pd.read_csv('dataset/sensing/wifi_location/wifi_location_' + uid + '.csv')\n",
    "    wifi_locations.reset_index(inplace = True)\n",
    "    wifi_locations.columns = (\"timestamp\", \"location\", \"null\")\n",
    "    wifi_locations = wifi_locations.drop(\"null\", 1)\n",
    "    wifi_locations['time'] = pd.to_datetime(wifi_locations['timestamp'], unit = 's')\n",
    "    wifi_locations['day'] = wifi_locations['time'].dt.dayofyear\n",
    "    return wifi_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_in_range(time_interval, convo_df, start_name, end_name): \n",
    "    \"\"\"\n",
    "    inputs: \n",
    "        time_interval -- formatted as (start time, end time, start day, end day)\n",
    "        convo_df -- a dataframe containing start and end timestamps for a duration measurement \n",
    "            (so this function can be used for darkness as well as conversation)\n",
    "        start_name -- name of the column indicating the start timestamp\n",
    "        end_name -- name of the column indicating the end timestamp. \n",
    "    outputs: \n",
    "        the total conversation duration in the time interval.\n",
    "        \n",
    "    Note -- I initially named this function for activity so the variable names reflect that, but it can be applied to\n",
    "    multiple sensor data. \n",
    "    \n",
    "    This function is is similar to the activity in range but applies to dataframes contianing durations so the approach is\n",
    "    slightly different.  \n",
    "    \"\"\"\n",
    "    # again, unpack interval. \n",
    "    start = time_interval[0]\n",
    "    end = time_interval[1]\n",
    "    start_day = time_interval[2]\n",
    "    end_day = time_interval[3]\n",
    "    \n",
    "    # look at relevant days \n",
    "    if start_day == end_day: \n",
    "        conv = convo_df[convo_df['day'] == start_day]\n",
    "    else: \n",
    "        conv = convo_df[convo_df['day'] == start_day].append(convo_df[convo_df['day'] == end_day])\n",
    "    \n",
    "    # turn the conversations into intervals. If none exist, the duration is 0. \n",
    "    try:\n",
    "        conv['interval'] = list(zip(pd.to_datetime(conv[start_name], unit = 's'), \n",
    "                                    pd.to_datetime(conv[end_name], unit = 's')))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    # this function returns the duration of conversation inside the desired interval for each time interval. \n",
    "    conv['desired duration'] = conv['interval'].apply(lambda x: conv_range(start, end, x))\n",
    "    conv = conv.dropna()\n",
    "    \n",
    "    # return the sum of all desired intervals. \n",
    "    return conv['desired duration'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_range(start, end, conv_interval): \n",
    "    \"\"\"\n",
    "    returns the amount of seconds of conversation are in the interval (start, end)\n",
    "    \"\"\"\n",
    "    conv_start = conv_interval[0]\n",
    "    conv_end = conv_interval[1]\n",
    "    \n",
    "    if conv_end < start: \n",
    "        return np.nan\n",
    "    \n",
    "    elif conv_start > end:\n",
    "        return np.nan\n",
    "    \n",
    "    elif conv_start >= start and conv_end >= end:\n",
    "        return end - conv_start \n",
    "    \n",
    "    elif conv_start <= start and conv_end <= end:\n",
    "        return conv_end - start\n",
    "    \n",
    "    elif conv_start >= start and conv_end <= end:\n",
    "        return conv_end - conv_start\n",
    "    \n",
    "    elif conv_start <= start and conv_end >= end:\n",
    "        return end - start\n",
    "    \n",
    "def convert_timedeltas(x): \n",
    "    \"\"\"\n",
    "    converts timedeltas to seconds, leaves any numbers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return x.seconds\n",
    "    except:\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_in_range(time_interval, activity_df, func = 'act'): \n",
    "    \"\"\"\n",
    "    inputs: \n",
    "        time_interval -- formatted as (start time, end time, start day, end day)\n",
    "        activity_df -- dataframe for a single user. \n",
    "    outputs: \n",
    "        the mean activity inference in the time interval.\n",
    "        \n",
    "    Note: the activity dataframe and variable names imply \n",
    "    \"\"\"\n",
    "    \n",
    "    # unpack the values from the time interval\n",
    "    start = time_interval[0]\n",
    "    end = time_interval[1]\n",
    "    start_day = time_interval[2]\n",
    "    end_day = time_interval[3]\n",
    "    \n",
    "    # only look at relevant days to say runtime\n",
    "    if start_day == end_day: \n",
    "        activity = activity_df[activity_df['day'] == start_day]\n",
    "    else: \n",
    "        activity = activity_df[activity_df['day'] == start_day].append(activity_df[activity_df['day'] == end_day])\n",
    "        \n",
    "    # this try except loop takes care of the case where the activity data is an empty dataframe, so we return Nan \n",
    "    try: \n",
    "        ### these cases are different for different func inputs so this function can be extensible. \n",
    "        \n",
    "        # in this case, we are looking at activity and taking the mean\n",
    "        if func == 'act':\n",
    "            return activity[activity['time'].apply(lambda x: time_in_range(start, end, x))][' activity inference'].sum()\n",
    "        elif func == 'all_act': \n",
    "            print(activity[activity['time'].apply(lambda x: time_in_range(start, end, x))][' activity inference'].values)\n",
    "            return activity[activity['time'].apply(lambda x: time_in_range(start, end, x))][' activity inference'].values\n",
    "        # in this case, we are looking at bluetooth and take the count\n",
    "        elif func == 'count':\n",
    "            return activity[activity['time'].apply(lambda x: time_in_range(start, end, x))].shape[0]\n",
    "        # in this case we apply the location variance function \n",
    "        elif func == 'location variance': \n",
    "            return location_variance(activity[activity['time'].apply(lambda x: time_in_range(start, end, x))])\n",
    "        elif func == 'location changes': \n",
    "            return num_changes(activity[activity['time'].apply(lambda x: time_in_range(start, end, x))])\n",
    "    except:\n",
    "        # if we find none in count, we return 0. If not, there is no data/average from there so return Nan. \n",
    "        if func == 'count': \n",
    "            return 0\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns a new dataframe with all of the activity durations for a particular student throughout the term.\n",
    "#Only activities longer than 1 minute were considered.\n",
    "#At the end, we dediced to use total activity duration (sum of activity durations per day) for our model\n",
    "\n",
    "def activity_analysis(uid):\n",
    "    activity = pd.read_csv('dataset/sensing/activity/activity_' + uid + '.csv')\n",
    "    activity = activity[activity[' activity inference'] !=3]\n",
    "    activity = activity.reset_index()\n",
    "    #Change the path as needed when running the files on your computer.\n",
    "    activity['day'] = pd.to_datetime(activity['timestamp'], unit = 's').dt.dayofyear\n",
    "    daily_activity = activity.groupby('day').mean()\n",
    "    def shift_counter_activity(data):\n",
    "        shift_num = 0\n",
    "        list_shift_num = []\n",
    "        list_time = []\n",
    "        list_day = []\n",
    "        for i in range(0, len(data)):\n",
    "            if data[' activity inference'][i] != 0:\n",
    "                try: \n",
    "                    if data[' activity inference'][i+1] != 0 and (data.index[i]+1) == data.index[i+1]:\n",
    "                        shift_num += 1\n",
    "                    else:\n",
    "                        list_shift_num.append(shift_num)\n",
    "                        shift_num = 0\n",
    "                except:\n",
    "                    list_shift_num.append(shift_num)\n",
    "                    shift_num = 0\n",
    "        return list_shift_num\n",
    "    activity_shifts = shift_counter_activity(activity)\n",
    "    edited_act = activity[activity[' activity inference'] !=0]\n",
    "    edited_act = edited_act.reset_index()\n",
    "    def shifts_only(list1):\n",
    "        shifts_only_list = []\n",
    "        for i in list1:\n",
    "            if i != 0:\n",
    "                shifts_only_list.append(i)\n",
    "        return shifts_only_list\n",
    "    new_activity_shifts = shifts_only(activity_shifts)\n",
    "    def get_sums(list1):\n",
    "        list_sums_b = []\n",
    "        for i in range(0,len(list1)+1):\n",
    "            new_list = list1[:i]\n",
    "            sums = sum(new_list)\n",
    "            list_sums_b.append(sums)\n",
    "        return list_sums_b\n",
    "    list_sums_before_activity = get_sums(activity_shifts)\n",
    "    def activity_dur(list_shift_num, data):\n",
    "        time_deltas = []\n",
    "        day = []\n",
    "        start_time = []\n",
    "        for i in range(0, len(list_shift_num)):\n",
    "            if i == 0:\n",
    "                time_deltas.append(data['timestamp'][list_shift_num[i]] - data['timestamp'][0])\n",
    "                day.append(data.day[list_shift_num[i]+i+list_sums_before_activity[i]])\n",
    "                start_time.append(data.timestamp[list_shift_num[i]+i+list_sums_before_activity[i]])\n",
    "            elif i != 0:\n",
    "                time_deltas.append(data['timestamp'][list_shift_num[i]+i+list_sums_before_activity[i]] - data['timestamp'][list_sums_before_activity[i]+i])\n",
    "                day.append(data.day[list_shift_num[i]+i+list_sums_before_activity[i]])\n",
    "                start_time.append(data.timestamp[list_shift_num[i]+i+list_sums_before_activity[i]])\n",
    "        dataframe = pd.DataFrame({'Time Delta': time_deltas, 'day': day, 'Start Time': start_time})\n",
    "        return dataframe\n",
    "    activity_dur_df = activity_dur(activity_shifts, edited_act)\n",
    "    activity_dur_df['end_time'] = activity_dur_df['Start Time'] + activity_dur_df['Time Delta']\n",
    "    activity_dur_df['start_day'] = pd.to_datetime(activity_dur_df['Start Time'], unit='s').dt.dayofyear\n",
    "    activity_dur_df['end_day'] = pd.to_datetime(activity_dur_df['end_time'], unit='s').dt.dayofyear\n",
    "    activity_dur_df = activity_dur_df.rename(columns={'Start Time': 'start_time'})\n",
    "    #activity_dur_df = activity_dur_df[activity_dur_df['Time Delta'] >= 60]\n",
    "    activity_dur_day = activity_dur_df.groupby('day')['Time Delta'].sum()\n",
    "    return activity_dur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deadlines_processing():\n",
    "    data = pd.read_csv('dataset/education/deadlines.csv')\n",
    "    data = data.dropna(axis=1, how='all')\n",
    "    data = data.T\n",
    "    old_names = list(data.columns)\n",
    "    new_names = data.iloc[0]\n",
    "    data.rename(columns=dict(zip(old_names, new_names)), inplace=True)\n",
    "    data = data.drop(['uid'])\n",
    "    data['doy'] = pd.to_datetime(data.index)\n",
    "    data['doy'] = data['doy'].dt.dayofyear\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u01</th>\n",
       "      <th>u02</th>\n",
       "      <th>u03</th>\n",
       "      <th>u04</th>\n",
       "      <th>u05</th>\n",
       "      <th>u07</th>\n",
       "      <th>u08</th>\n",
       "      <th>u09</th>\n",
       "      <th>u10</th>\n",
       "      <th>u12</th>\n",
       "      <th>...</th>\n",
       "      <th>u49</th>\n",
       "      <th>u50</th>\n",
       "      <th>u51</th>\n",
       "      <th>u52</th>\n",
       "      <th>u53</th>\n",
       "      <th>u54</th>\n",
       "      <th>u57</th>\n",
       "      <th>u58</th>\n",
       "      <th>u59</th>\n",
       "      <th>doy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3/27/2013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/28/2013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/29/2013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/30/2013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/31/2013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/1/2013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/2/2013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/3/2013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/4/2013</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/5/2013</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          u01 u02 u03 u04 u05 u07 u08 u09 u10 u12  ... u49 u50 u51 u52 u53  \\\n",
       "3/27/2013   0   0   0   0   0   0   0   0   0   1  ...   2   0   0   0   0   \n",
       "3/28/2013   0   0   0   0   0   0   0   0   0   0  ...   1   0   0   0   0   \n",
       "3/29/2013   0   0   0   0   0   0   0   0   0   0  ...   2   0   0   0   0   \n",
       "3/30/2013   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "3/31/2013   0   0   0   0   1   0   0   0   1   1  ...   0   0   0   1   0   \n",
       "...        ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..   \n",
       "6/1/2013    0   0   0   0   0   0   0   0   1   0  ...   0   0   0   1   0   \n",
       "6/2/2013    0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "6/3/2013    0   0   0   0   0   0   0   0   0   0  ...   1   0   0   0   0   \n",
       "6/4/2013    1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "6/5/2013    1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "          u54 u57 u58 u59  doy  \n",
       "3/27/2013   0   0   0   0   86  \n",
       "3/28/2013   0   0   0   0   87  \n",
       "3/29/2013   1   0   0   1   88  \n",
       "3/30/2013   0   0   0   0   89  \n",
       "3/31/2013   0   0   0   0   90  \n",
       "...        ..  ..  ..  ..  ...  \n",
       "6/1/2013    1   0   0   0  152  \n",
       "6/2/2013    0   0   0   0  153  \n",
       "6/3/2013    0   0   0   0  154  \n",
       "6/4/2013    0   0   0   0  155  \n",
       "6/5/2013    0   0   0   0  156  \n",
       "\n",
       "[71 rows x 45 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deadlines_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(hour): \n",
    "    if hour >= 18: \n",
    "        return 'evening'\n",
    "    elif hour < 10: \n",
    "        return 'night'\n",
    "    else:\n",
    "        return 'day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midterm(day): \n",
    "    if day < 21 + 86: \n",
    "        return 'pre midterm'\n",
    "    elif (21 + 86) <= day <= (35 + 86):\n",
    "        return 'in midterm'\n",
    "    elif (35 + 86) < day:\n",
    "        return 'post midterm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def ema_intervals_data(uid, window, ema_name, desired_column): \n",
    "    \"\"\"\n",
    "    inputs: uid -- user id \n",
    "            window -- the frame of time (in hours) of how long the interval of sensor collection around each EMA should be. \n",
    "    \n",
    "    Finds desired sensor data within that window of time before and after the EMA. \n",
    "    \n",
    "    Returns: a dataframe containing stress level and desired feature information for each stress response. If the\n",
    "    dataframe has less than 50 elements returns none (we assume there isn't enough data with less than 50 elements). \n",
    "    \"\"\"\n",
    "    data = process_stress_ema_remove_null(uid, ema_name, desired_column)\n",
    "    \n",
    "    # define the window of time we want to look at for each stress answer. \n",
    "    data['start_time'] = data['resp_time'] - pd.to_timedelta(window, unit = 'h')\n",
    "    data['end_time'] = data['resp_time'] + pd.to_timedelta(window, unit = 'h')\n",
    "    \n",
    "    data['hour'] = data['resp_time'].dt.hour\n",
    "    data['epoch'] = data['hour'].apply(epoch)\n",
    "    data = data.join(pd.get_dummies(data['epoch']))\n",
    "    \n",
    "    # this will reduce runtime by only looking at sensor data from that day then applying our interval function to it. \n",
    "    data['start_day'] = data['start_time'].dt.dayofyear\n",
    "    data['end_day'] = data['end_time'].dt.dayofyear\n",
    "    data['doy'] = data['resp_time'].dt.dayofyear\n",
    "    \n",
    "    data['dow'] = data['resp_time'].dt.dayofweek\n",
    "    data = data.join(pd.get_dummies(data['dow']))\n",
    "    data = data.rename(columns={0: 'Monday', \n",
    "                                1: 'Tuesday', \n",
    "                                2: 'Wednesday', \n",
    "                                3: 'Thursday', \n",
    "                                4: 'Friday',\n",
    "                                5: 'Saturday',\n",
    "                                6: 'Sunday'})\n",
    "    \n",
    "    data['midterm'] = data['doy'].apply(midterm)\n",
    "    data = data.join(pd.get_dummies(data['midterm']))\n",
    "    \n",
    "    # the time interval is just a tuple of (start time, end time)\n",
    "    # in the future, we will apply functions to the interval using other dataframes to return desired columns inside\n",
    "    # the interval\n",
    "    data['interval'] = tuple(zip(data['start_time'], data['end_time'], data['start_day'], data['end_day']))\n",
    "    \n",
    "    # load activity data\n",
    "    activity = activity_analysis(uid)\n",
    "    data['activity dur'] = data['interval'].apply(lambda x: conversation_in_range(x, activity, \n",
    "                                                                           'start_time', 'end_time'))\n",
    "    data['activity dur'] = data['activity dur'].apply(convert_timedeltas)\n",
    "    \n",
    "    # this will return the total conversation duration for each interval\n",
    "    conversation = load_conversation(uid)\n",
    "    data['conversation dur'] = data['interval'].apply(lambda x: conversation_in_range(x, conversation, \n",
    "                                                                           'start_timestamp', ' end_timestamp'))\n",
    "    data['conversation dur'] = data['conversation dur'].apply(convert_timedeltas)\n",
    "    \n",
    "    # find the total darkness duration for each interval\n",
    "    darkness = load_darkness(uid)\n",
    "    data['darkness dur'] = data['interval'].apply(lambda x: conversation_in_range(x, darkness, 'start', 'end'))\n",
    "    data['darkness dur'] = data['darkness dur'].apply(convert_timedeltas)\n",
    "    \n",
    "    \n",
    "    # find the number of bluetooth colocations in each interval\n",
    "    bluetooth = load_bluetooth(uid)\n",
    "    data['bluetooth colocations'] = data['interval'].apply(lambda x: activity_in_range(x, bluetooth, 'count'))\n",
    "    \n",
    "    \n",
    "    # find the location variance in each stress interval. \n",
    "    gps = load_gps(uid)\n",
    "    data['location variance'] = data['interval'].apply(lambda x: activity_in_range(x, gps, 'location variance'))\n",
    "    \n",
    "    # wifi locations\n",
    "    wifi_locations = load_wifi_locations(uid)\n",
    "    data['location changes'] = data['interval'].apply(lambda x: activity_in_range(x, wifi_locations, 'location changes'))\n",
    "    \n",
    "    #load deadlines data.\n",
    "    deadlines = deadlines_processing()\n",
    "    #deadlines = deadlines[deadlines['doy' == data.start_day]]\n",
    "    deadlines = deadlines[[uid, 'doy']]\n",
    "    data = pd.merge(data, deadlines, on='doy', how='inner')\n",
    "    data = data.rename(columns={uid: 'deadlines'})\n",
    "    \n",
    "    # drop Nan values\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # only use these features if we have over 50 datapoints\n",
    "    if data.shape[0] < 20: \n",
    "        return None\n",
    "    \n",
    "    data.sort_values(by=['resp_time'], inplace=True)\n",
    "    \n",
    "    # return relevant columns. \n",
    "    return data[['resp_time', desired_column, 'location changes', 'activity dur',\n",
    "                'conversation dur', 'darkness dur', 'bluetooth colocations', 'location variance', 'deadlines', \n",
    "                'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', \n",
    "                'day', 'evening', 'night', 'pre midterm', 'in midterm', 'post midterm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_time</th>\n",
       "      <th>level</th>\n",
       "      <th>location changes</th>\n",
       "      <th>activity dur</th>\n",
       "      <th>conversation dur</th>\n",
       "      <th>darkness dur</th>\n",
       "      <th>bluetooth colocations</th>\n",
       "      <th>location variance</th>\n",
       "      <th>deadlines</th>\n",
       "      <th>Monday</th>\n",
       "      <th>...</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>night</th>\n",
       "      <th>pre midterm</th>\n",
       "      <th>in midterm</th>\n",
       "      <th>post midterm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-03-27 04:45:45</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>28695.0</td>\n",
       "      <td>22</td>\n",
       "      <td>-12.090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-03-28 23:53:09</td>\n",
       "      <td>2</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7646.0</td>\n",
       "      <td>21876.0</td>\n",
       "      <td>51228.0</td>\n",
       "      <td>68</td>\n",
       "      <td>-12.437589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-29 19:45:25</td>\n",
       "      <td>3</td>\n",
       "      <td>157.0</td>\n",
       "      <td>8838.0</td>\n",
       "      <td>35328.0</td>\n",
       "      <td>33600.0</td>\n",
       "      <td>77</td>\n",
       "      <td>-11.756663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-30 00:32:58</td>\n",
       "      <td>1</td>\n",
       "      <td>129.0</td>\n",
       "      <td>7846.0</td>\n",
       "      <td>30553.0</td>\n",
       "      <td>36009.0</td>\n",
       "      <td>72</td>\n",
       "      <td>-12.251667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-30 22:27:26</td>\n",
       "      <td>3</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>28440.0</td>\n",
       "      <td>39258.0</td>\n",
       "      <td>73</td>\n",
       "      <td>-11.287779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-03-31 18:49:27</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2415.0</td>\n",
       "      <td>22767.0</td>\n",
       "      <td>40191.0</td>\n",
       "      <td>36</td>\n",
       "      <td>-18.334303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-04-01 02:45:54</td>\n",
       "      <td>4</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2642.0</td>\n",
       "      <td>31359.0</td>\n",
       "      <td>66770.0</td>\n",
       "      <td>8</td>\n",
       "      <td>-18.101422</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-04-03 06:03:04</td>\n",
       "      <td>3</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4674.0</td>\n",
       "      <td>15717.0</td>\n",
       "      <td>8004.0</td>\n",
       "      <td>64</td>\n",
       "      <td>-11.360860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-04-04 07:28:35</td>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2597.0</td>\n",
       "      <td>31086.0</td>\n",
       "      <td>19019.0</td>\n",
       "      <td>43</td>\n",
       "      <td>-12.848365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-04-05 06:08:42</td>\n",
       "      <td>2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3128.0</td>\n",
       "      <td>27195.0</td>\n",
       "      <td>29046.0</td>\n",
       "      <td>27</td>\n",
       "      <td>-14.231000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-04-06 01:26:41</td>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8261.0</td>\n",
       "      <td>40441.0</td>\n",
       "      <td>37840.0</td>\n",
       "      <td>13</td>\n",
       "      <td>-12.573852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-04-06 09:39:30</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3615.0</td>\n",
       "      <td>22478.0</td>\n",
       "      <td>16960.0</td>\n",
       "      <td>25</td>\n",
       "      <td>-13.795023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-04-07 21:21:54</td>\n",
       "      <td>3</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>35848.0</td>\n",
       "      <td>38781.0</td>\n",
       "      <td>17</td>\n",
       "      <td>-13.436662</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-04-09 04:50:01</td>\n",
       "      <td>3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>5766.0</td>\n",
       "      <td>22395.0</td>\n",
       "      <td>16201.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.031125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-04-10 02:59:22</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>30729.0</td>\n",
       "      <td>68278.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.709540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-04-10 22:33:15</td>\n",
       "      <td>3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3809.0</td>\n",
       "      <td>40229.0</td>\n",
       "      <td>66078.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.465318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013-04-11 02:03:16</td>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>30822.0</td>\n",
       "      <td>70286.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-12.078986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-04-12 02:44:19</td>\n",
       "      <td>3</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3232.0</td>\n",
       "      <td>29840.0</td>\n",
       "      <td>67177.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-12.600362</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013-04-13 22:54:36</td>\n",
       "      <td>2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4481.0</td>\n",
       "      <td>34501.0</td>\n",
       "      <td>25351.0</td>\n",
       "      <td>26</td>\n",
       "      <td>-13.465352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-04-14 23:14:15</td>\n",
       "      <td>3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2798.0</td>\n",
       "      <td>20225.0</td>\n",
       "      <td>32673.0</td>\n",
       "      <td>38</td>\n",
       "      <td>-18.184314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-04-16 01:52:24</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4752.0</td>\n",
       "      <td>31454.0</td>\n",
       "      <td>6930.0</td>\n",
       "      <td>19</td>\n",
       "      <td>-12.419169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-04-16 04:24:02</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2764.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>6930.0</td>\n",
       "      <td>18</td>\n",
       "      <td>-12.884251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013-04-17 04:01:47</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>29263.0</td>\n",
       "      <td>4314.0</td>\n",
       "      <td>42</td>\n",
       "      <td>-12.929812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013-04-19 00:32:42</td>\n",
       "      <td>2</td>\n",
       "      <td>152.0</td>\n",
       "      <td>11122.0</td>\n",
       "      <td>29736.0</td>\n",
       "      <td>24303.0</td>\n",
       "      <td>113</td>\n",
       "      <td>-12.072687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013-04-20 06:44:52</td>\n",
       "      <td>2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>6556.0</td>\n",
       "      <td>22925.0</td>\n",
       "      <td>17616.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.640815</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013-04-26 18:03:22</td>\n",
       "      <td>3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>8724.0</td>\n",
       "      <td>31695.0</td>\n",
       "      <td>51701.0</td>\n",
       "      <td>193</td>\n",
       "      <td>-7.992075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2013-04-28 07:47:46</td>\n",
       "      <td>4</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4201.0</td>\n",
       "      <td>16504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-14.424446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013-04-28 19:34:02</td>\n",
       "      <td>4</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>23132.0</td>\n",
       "      <td>20996.0</td>\n",
       "      <td>117</td>\n",
       "      <td>-15.512007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013-04-28 21:44:49</td>\n",
       "      <td>4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>23132.0</td>\n",
       "      <td>26352.0</td>\n",
       "      <td>122</td>\n",
       "      <td>-15.514636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013-04-29 05:50:08</td>\n",
       "      <td>5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>16488.0</td>\n",
       "      <td>55380.0</td>\n",
       "      <td>112</td>\n",
       "      <td>-15.836041</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2013-04-30 05:58:15</td>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15687.0</td>\n",
       "      <td>63</td>\n",
       "      <td>-13.619664</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             resp_time  level  location changes  activity dur  \\\n",
       "0  2013-03-27 04:45:45      2              64.0        1418.0   \n",
       "4  2013-03-28 23:53:09      2             123.0        7646.0   \n",
       "3  2013-03-29 19:45:25      3             157.0        8838.0   \n",
       "2  2013-03-30 00:32:58      1             129.0        7846.0   \n",
       "1  2013-03-30 22:27:26      3             134.0        2716.0   \n",
       "5  2013-03-31 18:49:27      3              47.0        2415.0   \n",
       "6  2013-04-01 02:45:54      4              46.0        2642.0   \n",
       "7  2013-04-03 06:03:04      3              85.0        4674.0   \n",
       "8  2013-04-04 07:28:35      2              57.0        2597.0   \n",
       "9  2013-04-05 06:08:42      2              61.0        3128.0   \n",
       "10 2013-04-06 01:26:41      2              57.0        8261.0   \n",
       "11 2013-04-06 09:39:30      1              60.0        3615.0   \n",
       "12 2013-04-07 21:21:54      3             101.0        6020.0   \n",
       "13 2013-04-09 04:50:01      3              81.0        5766.0   \n",
       "15 2013-04-10 02:59:22      4             108.0        3120.0   \n",
       "14 2013-04-10 22:33:15      3              75.0        3809.0   \n",
       "18 2013-04-11 02:03:16      3              36.0        2130.0   \n",
       "19 2013-04-12 02:44:19      3              63.0        3232.0   \n",
       "20 2013-04-13 22:54:36      2              91.0        4481.0   \n",
       "21 2013-04-14 23:14:15      3              55.0        2798.0   \n",
       "17 2013-04-16 01:52:24      3              35.0        4752.0   \n",
       "16 2013-04-16 04:24:02      3              30.0        2764.0   \n",
       "22 2013-04-17 04:01:47      3              87.0        3577.0   \n",
       "23 2013-04-19 00:32:42      2             152.0       11122.0   \n",
       "24 2013-04-20 06:44:52      2             103.0        6556.0   \n",
       "28 2013-04-26 18:03:22      3              86.0        8724.0   \n",
       "25 2013-04-28 07:47:46      4              71.0        4201.0   \n",
       "27 2013-04-28 19:34:02      4              46.0        1100.0   \n",
       "26 2013-04-28 21:44:49      4              43.0        1100.0   \n",
       "29 2013-04-29 05:50:08      5              21.0         219.0   \n",
       "30 2013-04-30 05:58:15      4              45.0        1041.0   \n",
       "\n",
       "    conversation dur  darkness dur  bluetooth colocations  location variance  \\\n",
       "0             6211.0       28695.0                     22         -12.090000   \n",
       "4            21876.0       51228.0                     68         -12.437589   \n",
       "3            35328.0       33600.0                     77         -11.756663   \n",
       "2            30553.0       36009.0                     72         -12.251667   \n",
       "1            28440.0       39258.0                     73         -11.287779   \n",
       "5            22767.0       40191.0                     36         -18.334303   \n",
       "6            31359.0       66770.0                      8         -18.101422   \n",
       "7            15717.0        8004.0                     64         -11.360860   \n",
       "8            31086.0       19019.0                     43         -12.848365   \n",
       "9            27195.0       29046.0                     27         -14.231000   \n",
       "10           40441.0       37840.0                     13         -12.573852   \n",
       "11           22478.0       16960.0                     25         -13.795023   \n",
       "12           35848.0       38781.0                     17         -13.436662   \n",
       "13           22395.0       16201.0                      1         -13.031125   \n",
       "15           30729.0       68278.0                      0         -13.709540   \n",
       "14           40229.0       66078.0                      0         -11.465318   \n",
       "18           30822.0       70286.0                      0         -12.078986   \n",
       "19           29840.0       67177.0                      6         -12.600362   \n",
       "20           34501.0       25351.0                     26         -13.465352   \n",
       "21           20225.0       32673.0                     38         -18.184314   \n",
       "17           31454.0        6930.0                     19         -12.419169   \n",
       "16           24000.0        6930.0                     18         -12.884251   \n",
       "22           29263.0        4314.0                     42         -12.929812   \n",
       "23           29736.0       24303.0                    113         -12.072687   \n",
       "24           22925.0       17616.0                      0         -11.640815   \n",
       "28           31695.0       51701.0                    193          -7.992075   \n",
       "25           16504.0           0.0                     71         -14.424446   \n",
       "27           23132.0       20996.0                    117         -15.512007   \n",
       "26           23132.0       26352.0                    122         -15.514636   \n",
       "29           16488.0       55380.0                    112         -15.836041   \n",
       "30               0.0       15687.0                     63         -13.619664   \n",
       "\n",
       "   deadlines  Monday  ...  Thursday  Friday  Saturday  Sunday  day  evening  \\\n",
       "0          0       0  ...         0       0         0       0    0        0   \n",
       "4          0       0  ...         1       0         0       0    0        1   \n",
       "3          0       0  ...         0       1         0       0    0        1   \n",
       "2          0       0  ...         0       0         1       0    0        0   \n",
       "1          0       0  ...         0       0         1       0    0        1   \n",
       "5          0       0  ...         0       0         0       1    0        1   \n",
       "6          0       1  ...         0       0         0       0    0        0   \n",
       "7          0       0  ...         0       0         0       0    0        0   \n",
       "8          0       0  ...         1       0         0       0    0        0   \n",
       "9          0       0  ...         0       1         0       0    0        0   \n",
       "10         0       0  ...         0       0         1       0    0        0   \n",
       "11         0       0  ...         0       0         1       0    0        0   \n",
       "12         0       0  ...         0       0         0       1    0        1   \n",
       "13         0       0  ...         0       0         0       0    0        0   \n",
       "15         0       0  ...         0       0         0       0    0        0   \n",
       "14         0       0  ...         0       0         0       0    0        1   \n",
       "18         0       0  ...         1       0         0       0    0        0   \n",
       "19         0       0  ...         0       1         0       0    0        0   \n",
       "20         0       0  ...         0       0         1       0    0        1   \n",
       "21         0       0  ...         0       0         0       1    0        1   \n",
       "17         0       0  ...         0       0         0       0    0        0   \n",
       "16         0       0  ...         0       0         0       0    0        0   \n",
       "22         0       0  ...         0       0         0       0    0        0   \n",
       "23         0       0  ...         0       1         0       0    0        0   \n",
       "24         0       0  ...         0       0         1       0    0        0   \n",
       "28         0       0  ...         0       1         0       0    0        1   \n",
       "25         0       0  ...         0       0         0       1    0        0   \n",
       "27         0       0  ...         0       0         0       1    0        1   \n",
       "26         0       0  ...         0       0         0       1    0        1   \n",
       "29         0       1  ...         0       0         0       0    0        0   \n",
       "30         1       0  ...         0       0         0       0    0        0   \n",
       "\n",
       "    night  pre midterm  in midterm  post midterm  \n",
       "0       1            1           0             0  \n",
       "4       0            1           0             0  \n",
       "3       0            1           0             0  \n",
       "2       1            1           0             0  \n",
       "1       0            1           0             0  \n",
       "5       0            1           0             0  \n",
       "6       1            1           0             0  \n",
       "7       1            1           0             0  \n",
       "8       1            1           0             0  \n",
       "9       1            1           0             0  \n",
       "10      1            1           0             0  \n",
       "11      1            1           0             0  \n",
       "12      0            1           0             0  \n",
       "13      1            1           0             0  \n",
       "15      1            1           0             0  \n",
       "14      0            1           0             0  \n",
       "18      1            1           0             0  \n",
       "19      1            1           0             0  \n",
       "20      0            1           0             0  \n",
       "21      0            1           0             0  \n",
       "17      1            1           0             0  \n",
       "16      1            1           0             0  \n",
       "22      1            0           1             0  \n",
       "23      1            0           1             0  \n",
       "24      1            0           1             0  \n",
       "28      0            0           1             0  \n",
       "25      1            0           1             0  \n",
       "27      0            0           1             0  \n",
       "26      0            0           1             0  \n",
       "29      1            0           1             0  \n",
       "30      1            0           1             0  \n",
       "\n",
       "[31 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ema_intervals_data('u01', 10, 'stress', 'level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut, TimeSeriesSplit\n",
    "\n",
    "def random_forest_importance(features, target, features_names, plot, cv): \n",
    "    \"\"\"\n",
    "    input: features: features of the machine learning model\n",
    "           target: labels for the machine learning model\n",
    "           features_names: the name of each feature column \n",
    "           plot: boolean, if True, plot the important features\n",
    "           cv: boolean, if True, return average cross validation score instead of feature importances. \n",
    "    given input features and targets (labels), a random forest model is created to find the importance of each feature to \n",
    "    the target. Plots these outcomes. \n",
    "    \"\"\"\n",
    "    # just from some guess and check, it seems that using 500 estimators greatly reduces the random element of the \n",
    "    # classifier\n",
    "    model = RandomForestClassifier(n_estimators = 500)\n",
    "    model.fit(features, target)\n",
    "    \n",
    "    if plot is True: \n",
    "        # to determine if the model is better than random chance(i.e. our important features are actually important),\n",
    "        # we can check with a cross validation score.\n",
    "        #print('average cross validation score: {:.2f}'.format(cross_val_score(RandomForestClassifier(n_estimators = 500),\n",
    "        #                                                                      features, target, cv = 3).mean()))\n",
    "        n_features = features.shape[1]\n",
    "        plot_feature_importance(n_features, features_names, model.feature_importances_)\n",
    "        \n",
    "    if cv is True: \n",
    "        \n",
    "        return tscvscore(features, target, RandomForestClassifier(n_estimators = 500), 5)\n",
    "        \n",
    "        \"\"\"tscv = TimeSeriesSplit(n_splits = 5)\n",
    "        avg_score = 0\n",
    "        \n",
    "        for train_index, test_index in tscv.split(features): \n",
    "            #print(train_index)\n",
    "            #print(test_index)\n",
    "            X_train, X_test = features[train_index], features[test_index]\n",
    "            y_train, y_test = target[train_index], target[test_index]\n",
    "            \n",
    "            forest = RandomForestClassifier(n_estimators = 500)\n",
    "            forest.fit(X_train, y_train)\n",
    "            score = forest.score(X_test, y_test)\n",
    "            #print(train_index, test_index, score)\n",
    "            avg_score += score/5\n",
    "            #print(avg_score)\n",
    "            \n",
    "        return avg_score\"\"\"\n",
    "    \n",
    "    return model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(n_features, features_names, feature_importance): \n",
    "    \"\"\"\n",
    "    input: n_features: number of features\n",
    "           features_names: names of features\n",
    "           feature_importance: the importance of each feature\n",
    "    makes a bar plot showing the importance of each feature. \n",
    "    \"\"\"\n",
    "    plt.barh(range(n_features), feature_importance, align='center')\n",
    "    plt.yticks(np.arange(n_features), features_names)\n",
    "    plt.xlabel('feature importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cv_scores(uid, window, ema, desired_column, feature_names, data = None): \n",
    "    \"\"\"\n",
    "    inputs: uid -- user id\n",
    "            window -- timeframe to examine\n",
    "            plot -- if true, plots results\n",
    "            cv -- if true, returns cross validation scores from stress prediction. \n",
    "            \n",
    "    Finds the intervals of stress around the ema response within the window, predicts stress with those sensor data. \n",
    "    returns the feature importance of that stress prediction along with the feature names. \n",
    "    \"\"\"\n",
    "    \n",
    "    # load intervals\n",
    "    if data is None: \n",
    "        data = ema_intervals_data(uid, window, ema, desired_column)\n",
    "    \n",
    "    feature_names = ['location changes', 'activity dur',\n",
    "                'conversation dur', 'darkness dur', 'bluetooth colocations', 'location variance', 'deadlines', \n",
    "                'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', \n",
    "                'day', 'evening', 'night', 'pre midterm', 'in midterm', 'post midterm']\n",
    "    features = data[feature_names].values\n",
    "    \n",
    "    target = data[desired_column].values\n",
    "    \n",
    "    #feat_import = perm_importance(features, target, feature_names, plot) \n",
    "    feat_import = random_forest_importance(features, target, feature_names, plot=False, cv=True)\n",
    "    \n",
    "    return feat_import, feature_names    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_window_cvs(uid, windows, ema, desired_column, data, feature_names, plot=False): \n",
    "    \"\"\"\n",
    "    input: uid -- user id\n",
    "           windows -- list of windows to look at \n",
    "           plot -- boolean that, if true, plots results\n",
    "    \n",
    "    This function loops through all the windows and finds cross validation scores for stress prediction using the \n",
    "    window of time sensors. \n",
    "    \n",
    "    Returns a row of a dataframe corresponding to the maximimum cross validation value and its window of time. \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    # loop through all the windows\n",
    "    for window in windows: \n",
    "        # this function returns the cross validation of the uid's stress EMA for the given window i\n",
    "        need = data[data['window'] == window]\n",
    "        cv = find_cv_scores(uid, window, ema, desired_column, feature_names, need)[0]\n",
    "        # add the window and cv score to a dataframe\n",
    "        df = df.append(pd.DataFrame({'window': window, 'cross validation score': cv}, index = [0]))\n",
    "    \n",
    "    # this will make a scatter of the dataframe\n",
    "    if plot is True: \n",
    "        sns.relplot(x='window', y = 'cross validation score', data = df)\n",
    "    \n",
    "    # return the row \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_windows(windows, ema, desired_column, data, feature_names): \n",
    "    \"\"\"\n",
    "    input: windows -- list of windows to look at. \n",
    "    \n",
    "    Loops through all user ids and finds the best (highest cv score) window out of the windows list \n",
    "    \n",
    "    returns a dataframe with each uid and its optimal window with cross validation score. \n",
    "    \"\"\"   \n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    ema_files = glob.glob('dataset/EMA/response/' + ema + '/' + ema + '_*.json')\n",
    "    uid_start = len('dataset/EMA/response/' + ema + '/' + ema + '_')\n",
    "    # loops through all the files and averages the feature importance lists\n",
    "    for file in ema_files: \n",
    "        # the uid indexed from the file text\n",
    "        uid = file[uid_start:uid_start+3]\n",
    "        if uid not in {'u01'}:\n",
    "            continue\n",
    "        # if there aren't enough datapoints, the max_window function will throw an error, so I used a try except loop.\n",
    "        need = data[data['uid'] == uid]\n",
    "        x = find_window_cvs(uid, windows, ema, desired_column, need, feature_names)\n",
    "        x['uid'] = uid\n",
    "        max_window = x[x['cross validation score'] == x['cross validation score'].max()]\n",
    "        df = df.append(max_window, ignore_index = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_best_windows(best_windows, feature_names, data, desired_column): \n",
    "    \"\"\"\n",
    "    inputs: \n",
    "        best_windows: dataframe containing uid and the best window for each uids\n",
    "        feature_names: the names of each feature. \n",
    "    outputs: \n",
    "        new best parameters and cross validation scores in a dataframe created from random parameter searching the random \n",
    "        forest models. \n",
    "    \"\"\"    \n",
    "    results = pd.DataFrame()  \n",
    "    \n",
    "    for uid in best_windows['uid'].unique(): \n",
    "        values = best_windows[best_windows['uid'] == uid].iloc[0]\n",
    "        window = values['window']\n",
    "        \n",
    "        need = data[data['uid'] == uid]\n",
    "        need = need[need['window'] == window]\n",
    "        features = need[feature_names].values\n",
    "        target = need[desired_column].values\n",
    "        \n",
    "        best_params, best_score = forest_gridsearch(features, target)\n",
    "        best_params['score'] = [best_score]\n",
    "        best_params['uid'] = [uid]\n",
    "        best_params['window'] = [window]\n",
    "        results = results.append(pd.DataFrame(best_params), ignore_index=True)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "def forest_gridsearch(features, target): \n",
    "    \"\"\"\n",
    "    adapted from \n",
    "    https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "    performs a random parameter search on the random forest model and returns the best parameters and best score. \n",
    "    \"\"\"\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [x*100 for x in range(1, 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [x*10 for x in range(1, 10)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    \n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestClassifier()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, \n",
    "                                   cv = 5, verbose=2, random_state=0, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(features, target)\n",
    "    \n",
    "    return rf_random.best_params_, rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(windows, ema, desired_column):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    ema_files = glob.glob('dataset/EMA/response/' + ema + '/' + ema + '_*.json')\n",
    "    uid_start = len('dataset/EMA/response/' + ema + '/' + ema + '_')\n",
    "    # loops through all the files and averages the feature importance lists\n",
    "    for file in ema_files: \n",
    "        uid = file[uid_start:uid_start+3]\n",
    "        if uid not in {'u01'}: \n",
    "            continue\n",
    "        for window in windows: \n",
    "            data = ema_intervals_data(uid, window, ema, desired_column)\n",
    "            data['uid'] = uid\n",
    "            data['window'] = window\n",
    "            df = df.append(data)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_funcs(windows, ema, desired_column, feature_names): \n",
    "    \n",
    "    data = aggregate_data(windows, ema, desired_column)\n",
    "    best_windows = optimize_windows(windows, ema, desired_column, data, feature_names)\n",
    "    best_funcs = search_best_windows(best_windows, feature_names, data, desired_column)\n",
    "    \n",
    "    return best_funcs, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def perm_importance(features, target, n_estimators, min_samples_split, min_samples_leaf, max_features, \n",
    "                   max_depth, bootstrap, feature_names): \n",
    "    \"\"\"\n",
    "    input: features: features of the machine learning model\n",
    "           target: labels for the machine learning model\n",
    "           features_names: the name of each feature column \n",
    "           plot: boolean, if True, plot the important features\n",
    "    \n",
    "    uses permutation importance with a time series split to return the average feature importance for each split along with \n",
    "    the standard deviation of that feature importance\n",
    "    \"\"\"\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits = 5)\n",
    "    \n",
    "    # zeros(num features)\n",
    "    avg_importance = zeros(len(feature_names))\n",
    "    avg_std = zeros(len(feature_names))\n",
    "    \n",
    "    for train_index, test_index in tscv.split(features): \n",
    "            \n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, min_samples_split=min_samples_split,\n",
    "                                      min_samples_leaf=min_samples_leaf, max_features=max_features,\n",
    "                                      max_depth=max_depth, bootstrap=bootstrap)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #print('prediction: {}'.format(model.predict(X_test)))\n",
    "        #print('acutal: {}'.format(y_test))\n",
    "        \n",
    "        r = permutation_importance(model, X_test, y_test, n_repeats = 30, random_state = 0)\n",
    "        \n",
    "        avg_importance = avg_importance + r.importances_mean/5\n",
    "        avg_std = avg_std + r.importances_std/5\n",
    "            \n",
    "        print(r.importances_mean)\n",
    "        print(r.importances_std)\n",
    "    \n",
    "    return avg_importance, avg_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_heatmap(data): \n",
    "    corr = data.corr()\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    ax = sns.heatmap(\n",
    "        corr, \n",
    "        vmin=-1, vmax=1, center=0,\n",
    "        #cmap=sns.diverging_palette(20, 220, n=200),\n",
    "        square=True\n",
    "    )\n",
    "    \n",
    "    ax.set_xticklabels(\n",
    "        ax.get_xticklabels(),\n",
    "        rotation=45,\n",
    "        horizontalalignment='right'\n",
    "    )\n",
    "\n",
    "    return data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_feature_importance(windows, ema, desired_column, feature_names): \n",
    "    \n",
    "    #feature_names = ['location changes', 'activity dur',\n",
    "    #           'conversation dur', 'darkness dur', 'bluetooth colocations', 'location variance', 'deadlines', \n",
    "    #            'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', \n",
    "    #            'day', 'evening', 'night', 'pre midterm', 'in midterm', 'post midterm']\n",
    "    \n",
    "    # returns best_functions dataframe with parameters for random forest, uid, window, data = overall data\n",
    "    best_functions, data = find_best_funcs(windows, ema, desired_column, feature_names)\n",
    "    \n",
    "    print(best_functions)\n",
    "\n",
    "    \n",
    "    scoring_df = pd.DataFrame()\n",
    "    for i in best_functions.index:\n",
    "        row = best_functions.iloc[i]\n",
    "        n_estimators = row['n_estimators']\n",
    "        min_samples_split = row['min_samples_split']\n",
    "        min_samples_leaf = row['min_samples_leaf']\n",
    "        max_features = row['max_features']\n",
    "        max_depth = row['max_depth']\n",
    "        bootstrap = row['bootstrap']\n",
    "        viewing = data[data['uid'] == row['uid']]\n",
    "        viewing = viewing[viewing['window'] == row['window']]\n",
    "        features = viewing[feature_names].values\n",
    "        target = viewing[desired_column].values\n",
    "        \n",
    "        \n",
    "        test_df = test_best_models(features, target, \n",
    "                                                           n_estimators, min_samples_split, \n",
    "                                                           min_samples_leaf, max_features, \n",
    "                                                           max_depth, bootstrap)\n",
    "        \n",
    "        \n",
    "        scoring_df = scoring_df.append(pd.DataFrame({'uid': row['uid'],\n",
    "                                                     'primary score': test_df['primary'].mean(), \n",
    "                                                     'primary std': test_df['primary'].std(),\n",
    "                                                     'corrupted score': test_df['random'].mean(), \n",
    "                                                     'corrupted std': test_df['random'].std()}))\n",
    "        \n",
    "        #feat_importance = perm_importance(features, target, n_estimators, min_samples_split, min_samples_leaf, max_features, \n",
    "        #           max_depth, bootstrap, feature_names)\n",
    "        #feat_imp_df = feat_imp_df.append(pd.DataFrame({'uid': row['uid'], 'importance': feat_importance[0], \n",
    "        #                                              'std': feat_importance[1], 'sensor': feature_names}))\n",
    "    \n",
    "    scoring_df['difference'] = scoring_df['primary score'] - scoring_df['corrupted score']\n",
    "    \n",
    "    return scoring_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_models(features, target, n_estimators, min_samples_split, min_samples_leaf, max_features, \n",
    "                   max_depth, bootstrap):\n",
    "    \"\"\"\n",
    "    given the input best model for a certain user. This function fits the data for that user, finds the score on a test set,\n",
    "    then shuffles the y labels and does it again.     \n",
    "    \"\"\"\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, min_samples_split=min_samples_split,\n",
    "                                      min_samples_leaf=min_samples_leaf, max_features=max_features,\n",
    "                                      max_depth=max_depth, bootstrap=bootstrap)\n",
    "    \n",
    "    #for i in range(10): \n",
    "    \n",
    "    #    primary_score = cross_val_score(model, features, target)\n",
    "    #    print(primary_score, primary_score.mean())\n",
    "    #    print(tscvscore(features, target, model, 5))\n",
    "    \n",
    "    primary_scores = []\n",
    "    random_scores = []\n",
    "    \n",
    "    for i in range(10): \n",
    "    \n",
    "        primary_score = cross_val_score(model, features, target)\n",
    "        #print(tscvscore(features, target, model, 5))\n",
    "    \n",
    "        np.random.shuffle(target)\n",
    "    \n",
    "        randomized_score = cross_val_score(model, features, target)\n",
    "        #print(tscvscore(features, target, model, 5))\n",
    "        \n",
    "        primary_scores.append(primary_score)\n",
    "        random_scores.append(randomized_score)\n",
    "    \n",
    "    df = pd.DataFrame({'primary': primary_scores, 'random': random_scores})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_vs_random(window, ema, desired_column, uid_list): \n",
    "    \n",
    "    for uid in uid_list: \n",
    "        data = ema_intervals_data(uid, window, ema, desired_column)\n",
    "    \n",
    "        feature_names = ['location changes', 'activity dur',\n",
    "                    'conversation dur', 'darkness dur', 'bluetooth colocations', 'location variance', 'deadlines', \n",
    "                    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', \n",
    "                    'day', 'evening', 'night', 'pre midterm', 'in midterm', 'post midterm']\n",
    "    \n",
    "        features = data[feature_names]\n",
    "        target = data[desired_column]\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "        \n",
    "        \n",
    "        primary_score = cross_val_score(model, features, target).mean()\n",
    "        \n",
    "        randomized_score = cross_val_score(model, features, target).mean()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tscvscore(features, target, model, n_splits): \n",
    "    tscv = TimeSeriesSplit(n_splits = 5)\n",
    "    avg_score = 0\n",
    "        \n",
    "    for train_index, test_index in tscv.split(features): \n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "            \n",
    "       \n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        #print(\"train indices: {}, test indices: {}, score: {:.2f}\".format(train_index, test_index, score))\n",
    "        #print(\"predictions: {}, actual: {}\".format(model.predict(X_test), target[test_index]))\n",
    "        avg_score += score/5\n",
    "            \n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "def validate_user(uid, window, ema_name, desired_column, feature_names):\n",
    "    \n",
    "    data = ema_intervals_data(uid, window, ema_name, desired_column)\n",
    "    features = data[feature_names].values\n",
    "    target = data[desired_column].values\n",
    "    \n",
    "    extra_trees = ExtraTreesClassifier()\n",
    "    random_forest = RandomForestClassifier()\n",
    "    \n",
    "    et_scores = []\n",
    "    rf_scores = []\n",
    "    \n",
    "   \n",
    "    for i in range(10): \n",
    "    \n",
    "        et_scores.append(tscvscore(features, target, extra_trees, 5))\n",
    "        rf_scores.append(tscvscore(features, target, random_forest, 5))\n",
    "                         \n",
    "    cor_et_scores = []\n",
    "    cor_rf_scores = []\n",
    "    \n",
    "    for i in range(10): \n",
    "        \n",
    "        np.random.shuffle(target)\n",
    "    \n",
    "        cor_et_scores.append(tscvscore(features, target, extra_trees, 5))\n",
    "        cor_rf_scores.append(tscvscore(features, target, random_forest, 5))\n",
    "\n",
    "    return pd.DataFrame({'et score': et_scores, \n",
    "                         'rf score': rf_scores, \n",
    "                         'corrupted et score': cor_et_scores, \n",
    "                         'corrupted rf score': cor_rf_scores, \n",
    "                         'uid': uid, \n",
    "                         'window': window})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lowell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Lowell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    " feature_names = ['location changes', 'activity dur',\n",
    "                    'conversation dur', 'darkness dur', 'bluetooth colocations', 'location variance', 'deadlines']\n",
    "\n",
    "u17 = validate_user('u59', 4, 'stress', 'level', feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et score</th>\n",
       "      <th>rf score</th>\n",
       "      <th>corrupted et score</th>\n",
       "      <th>corrupted rf score</th>\n",
       "      <th>uid</th>\n",
       "      <th>window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.526829</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.482927</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.502439</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>0.434146</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.478049</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.526829</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.478049</td>\n",
       "      <td>0.507317</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.517073</td>\n",
       "      <td>0.497561</td>\n",
       "      <td>0.434146</td>\n",
       "      <td>0.448780</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.502439</td>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.502439</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.517073</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.517073</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.502439</td>\n",
       "      <td>0.492683</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   et score  rf score  corrupted et score  corrupted rf score  uid  window\n",
       "0  0.512195  0.526829            0.512195            0.482927  u59       4\n",
       "1  0.507317  0.502439            0.458537            0.434146  u59       4\n",
       "2  0.507317  0.536585            0.478049            0.463415  u59       4\n",
       "3  0.512195  0.526829            0.414634            0.458537  u59       4\n",
       "4  0.487805  0.536585            0.478049            0.507317  u59       4\n",
       "5  0.517073  0.497561            0.434146            0.448780  u59       4\n",
       "6  0.507317  0.536585            0.468293            0.463415  u59       4\n",
       "7  0.502439  0.507317            0.502439            0.400000  u59       4\n",
       "8  0.517073  0.512195            0.517073            0.512195  u59       4\n",
       "9  0.507317  0.507317            0.502439            0.492683  u59       4"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et score</th>\n",
       "      <th>rf score</th>\n",
       "      <th>corrupted et score</th>\n",
       "      <th>corrupted rf score</th>\n",
       "      <th>window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.507805</td>\n",
       "      <td>0.519024</td>\n",
       "      <td>0.476585</td>\n",
       "      <td>0.466341</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008433</td>\n",
       "      <td>0.015288</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.497561</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.460976</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.519512</td>\n",
       "      <td>0.478049</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.534146</td>\n",
       "      <td>0.502439</td>\n",
       "      <td>0.490244</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.517073</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.517073</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        et score   rf score  corrupted et score  corrupted rf score  window\n",
       "count  10.000000  10.000000           10.000000           10.000000    10.0\n",
       "mean    0.507805   0.519024            0.476585            0.466341     4.0\n",
       "std     0.008433   0.015288            0.033800            0.034278     0.0\n",
       "min     0.487805   0.497561            0.414634            0.400000     4.0\n",
       "25%     0.507317   0.507317            0.460976            0.451220     4.0\n",
       "50%     0.507317   0.519512            0.478049            0.463415     4.0\n",
       "75%     0.512195   0.534146            0.502439            0.490244     4.0\n",
       "max     0.517073   0.536585            0.517073            0.512195     4.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u17.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lowell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Lowell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['location changes', 'activity dur',\n",
    "                    'conversation dur', 'darkness dur', 'bluetooth colocations', 'location variance', 'deadlines',\n",
    "                 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', \n",
    "                    'day', 'evening', 'night', 'pre midterm', 'in midterm', 'post midterm']\n",
    "\n",
    "u = validate_user('u59', 4, 'stress', 'level', feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et score</th>\n",
       "      <th>rf score</th>\n",
       "      <th>corrupted et score</th>\n",
       "      <th>corrupted rf score</th>\n",
       "      <th>uid</th>\n",
       "      <th>window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.443902</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.478049</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.453659</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.497561</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.434146</td>\n",
       "      <td>0.482927</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>0.453659</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.453659</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.473171</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.453659</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.478049</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.448780</td>\n",
       "      <td>0.526829</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.434146</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.497561</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.448780</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.443902</td>\n",
       "      <td>0.478049</td>\n",
       "      <td>0.419512</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.429268</td>\n",
       "      <td>0.482927</td>\n",
       "      <td>0.424390</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.443902</td>\n",
       "      <td>0.517073</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>u59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   et score  rf score  corrupted et score  corrupted rf score  uid  window\n",
       "0  0.443902  0.487805            0.487805            0.478049  u59       4\n",
       "1  0.453659  0.468293            0.439024            0.497561  u59       4\n",
       "2  0.434146  0.482927            0.458537            0.453659  u59       4\n",
       "3  0.453659  0.512195            0.414634            0.473171  u59       4\n",
       "4  0.453659  0.458537            0.468293            0.478049  u59       4\n",
       "5  0.448780  0.526829            0.439024            0.434146  u59       4\n",
       "6  0.414634  0.497561            0.463415            0.448780  u59       4\n",
       "7  0.443902  0.478049            0.419512            0.487805  u59       4\n",
       "8  0.429268  0.482927            0.424390            0.409756  u59       4\n",
       "9  0.443902  0.517073            0.409756            0.409756  u59       4"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et score</th>\n",
       "      <th>rf score</th>\n",
       "      <th>corrupted et score</th>\n",
       "      <th>corrupted rf score</th>\n",
       "      <th>window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.441951</td>\n",
       "      <td>0.491220</td>\n",
       "      <td>0.442439</td>\n",
       "      <td>0.457073</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012637</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>0.026123</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.479268</td>\n",
       "      <td>0.420732</td>\n",
       "      <td>0.437805</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.443902</td>\n",
       "      <td>0.485366</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.452439</td>\n",
       "      <td>0.508537</td>\n",
       "      <td>0.462195</td>\n",
       "      <td>0.478049</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.453659</td>\n",
       "      <td>0.526829</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.497561</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        et score   rf score  corrupted et score  corrupted rf score  window\n",
       "count  10.000000  10.000000           10.000000           10.000000    10.0\n",
       "mean    0.441951   0.491220            0.442439            0.457073     4.0\n",
       "std     0.012637   0.021942            0.026123            0.031281     0.0\n",
       "min     0.414634   0.458537            0.409756            0.409756     4.0\n",
       "25%     0.436585   0.479268            0.420732            0.437805     4.0\n",
       "50%     0.443902   0.485366            0.439024            0.463415     4.0\n",
       "75%     0.452439   0.508537            0.462195            0.478049     4.0\n",
       "max     0.453659   0.526829            0.487805            0.497561     4.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
